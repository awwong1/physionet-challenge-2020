{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy as np, os, sys\n",
    "from scipy.io import loadmat\n",
    "import joblib\n",
    "from run_12ECG_classifier import load_12ECG_model, run_12ECG_classifier\n",
    "from driver import get_classes, load_challenge_data\n",
    "from get_12ECG_features import get_12ECG_features\n",
    "sys.path.append(os.path.abspath(\"./datasets\"))\n",
    "sys.path.append(os.path.abspath(\"./evaluation-2020/\"))\n",
    "sys.path.append(os.path.abspath(\"./models/\"))\n",
    "sys.path.append(os.path.abspath(\"./util/\"))\n",
    "\n",
    "from helper import translate_x, translate_y, get_data_from_physionet2020Dataset\n",
    "from physionet2020 import PhysioNet2020Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import evaluate_12ECG_score\n",
    "import argparse\n",
    "import json\n",
    "import keras\n",
    "import random\n",
    "import util\n",
    "import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-37eb93326ff8>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # use id from $ nvidia-smi\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tensorboard\n",
    "%load_ext tensorboard\n",
    "from tensorflow import keras\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
    "file_writer.set_as_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (3497, 4096, 12)\n",
      "Y:  (3497, 9)\n",
      "X:  (13946, 4096, 12)\n",
      "Y:  (13946, 9)\n"
     ]
    }
   ],
   "source": [
    "train_records, val_records = PhysioNet2020Dataset.split_names_cv(\n",
    "    \"Training_WFDB\", 5, 0\n",
    ")\n",
    "\n",
    "dev_x, dev_y = get_data_from_physionet2020Dataset(val_records)\n",
    "train_x, train_y = get_data_from_physionet2020Dataset(train_records)\n",
    "train_y = np.concatenate((train_y[:, :3], train_y[:, 4:]), axis=1)\n",
    "dev_y = np.concatenate((dev_y[:, :3], dev_y[:, 4:]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1dAVb, RBBB, LBBB, SB, atrial fibrillation (AF), sinus tachycardia (ST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\"AF\", \"I-AVB\", \"LBBB\", \"Normal\", \"PAC\", \"PVC\", \"RBBB\", \"STD\", \"STE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brazil = [0, 1, 2, 3, 4, 5]\n",
    "# physin = [1, 6, 2, 4/5, 0, 7/8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13946, 8)\n",
      "(3497, 8)\n"
     ]
    }
   ],
   "source": [
    "print (train_y.shape)\n",
    "print (dev_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_evaluation(probs, labels):\n",
    "    \n",
    "    threshold = 0.2\n",
    "\n",
    "    probs_class = probs\n",
    "    probs_class[probs_class > threshold] = 1\n",
    "    probs_class[probs_class <= threshold] = 0\n",
    "    probs_normal = np.sum(probs_class, axis=1).T\n",
    "    probs_normal = probs_normal.reshape(probs.shape[0], 1)\n",
    "    probs_normal[probs_normal == 0] = -1\n",
    "    probs_normal[probs_normal >= 1] = 0\n",
    "    probs_normal[probs_normal == -1] = 1\n",
    "    probs = np.concatenate((probs, probs_normal), axis=1)\n",
    "    \n",
    "    \n",
    "    label_normal = np.sum(labels, axis=1).T\n",
    "    label_normal = label_normal.reshape(probs.shape[0], 1)\n",
    "    label_normal[label_normal == 0] = -1\n",
    "    label_normal[label_normal >= 1] = 0\n",
    "    label_normal[label_normal == -1] = 1\n",
    "    labels = np.concatenate((labels, label_normal), axis=1)\n",
    "\n",
    "    probs_class = probs\n",
    "    probs_class[probs_class > threshold] = 0.99\n",
    "    probs_class[probs_class <= threshold] = 0.01\n",
    "    probs_test = probs_class\n",
    "\n",
    "    sys.path.append(os.path.abspath(\"../physionet-challenge-2020/evaluation-2020/\"))\n",
    "    import evaluate_12ECG_score\n",
    "#     auroc,auprc = evaluate_12ECG_score.compute_auc(labels, probs_test, 9)\n",
    "    auroc,auprc = evaluate_12ECG_score.compute_auc(labels, probs_test, 9)\n",
    "\n",
    "    probs_class = probs\n",
    "    probs_class[probs_class > threshold] = 1\n",
    "    probs_class[probs_class <= threshold] = 0\n",
    "    probs_test = probs_class\n",
    "#     accuracy,f_measure,f_beta,g_beta = evaluate_12ECG_score.compute_beta_score(labels, probs_test, 2, 9)\n",
    "    accuracy,f_measure,f_beta,g_beta = evaluate_12ECG_score.compute_beta_score(labels, probs_test, 2, 9)\n",
    "\n",
    "    print ([auroc,auprc,accuracy,f_measure,f_beta,g_beta])\n",
    "    \n",
    "    return {\n",
    "        'auroc': auroc,\n",
    "        'auprc': auprc,\n",
    "        'accuracy': accuracy,\n",
    "        'f_measure': f_measure,\n",
    "        'f_beta': f_beta,\n",
    "        'g_beta': g_beta\n",
    "    }\n",
    "\n",
    "class validationDataCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, valid_data):\n",
    "        super(validationDataCallback, self).__init__()\n",
    "        self.valid_data = valid_data\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        x_test = self.valid_data[0]\n",
    "        y_test = self.valid_data[1]\n",
    "        predictions = self.model.predict(x_test, batch_size=32, verbose=1)\n",
    "        epoch_data = epoch_evaluation(predictions, y_test)\n",
    "        for key, value in epoch_data.items():\n",
    "            tf.summary.scalar(key, data=value, step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "softmax 8\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from automodel import model\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint,\n",
    "                             TensorBoard, ReduceLROnPlateau,\n",
    "                             CSVLogger, EarlyStopping)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# model_6labels = load_model('../automatic-ecg-diagnosis/model.hdf5', compile=False)\n",
    "\n",
    "# weight = model_6labels.get_weights()\n",
    "\n",
    "# weight[-2] = np.hstack([weight[-2], np.random.randint(2, size=[weight[-2].shape[0], 2])])\n",
    "# bias = np.zeros(8)\n",
    "# bias[:6] = weight[-1]\n",
    "# weight[-1] = bias\n",
    "\n",
    "# model.set_weights(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'binary_crossentropy'\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "opt = Adam(lr)\n",
    "\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=7,\n",
    "                               min_lr=lr / 100),\n",
    "             EarlyStopping(patience=9,  # Patience should be larger than the one in ReduceLROnPlateau\n",
    "                           min_delta=0.00001),\n",
    "             validationDataCallback([dev_x, dev_y])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11156 samples, validate on 2790 samples\n",
      "Epoch 1/70\n",
      "3497/3497 [==============================] - 2s 644us/sample\n",
      "[0.4987007361869732, 0.11930319808496065, 0.7555863845810831, 0.07575707615536843, 0.1240094086545103, 0.04576723669271357]\n",
      "11156/11156 [==============================] - 24s 2ms/sample - loss: 0.4889 - val_loss: 0.3797\n",
      "Epoch 2/70\n",
      "3497/3497 [==============================] - 2s 429us/sample\n",
      "[0.4972550756488689, 0.11891116661353368, 0.7614659201638343, 0.07555166335691102, 0.1209154644354942, 0.04474075612038317]\n",
      "11156/11156 [==============================] - 21s 2ms/sample - loss: 0.4371 - val_loss: 0.4065\n",
      "Epoch 3/70\n",
      "3497/3497 [==============================] - 2s 442us/sample\n",
      "[0.4920154989279649, 0.11777467858435256, 0.7684354820063088, 0.07064429407881173, 0.11113844525406079, 0.041148607473816136]\n",
      "11156/11156 [==============================] - 20s 2ms/sample - loss: 0.4270 - val_loss: 0.3926\n",
      "Epoch 4/70\n",
      "3497/3497 [==============================] - 1s 418us/sample\n",
      "[0.49699459622652753, 0.11891766124774314, 0.7534889098085847, 0.0787610202527067, 0.1249398621267107, 0.04605429511821141]\n",
      "11156/11156 [==============================] - 20s 2ms/sample - loss: 0.4213 - val_loss: 0.3674\n",
      "Epoch 5/70\n",
      "3497/3497 [==============================] - 2s 430us/sample\n",
      "[0.49418042218951985, 0.11826641002732201, 0.7539788711071475, 0.08685147790843889, 0.1306306504219256, 0.048144664399230805]\n",
      "11156/11156 [==============================] - 20s 2ms/sample - loss: 0.4097 - val_loss: 0.3743\n",
      "Epoch 6/70\n",
      "3497/3497 [==============================] - 2s 454us/sample\n",
      "[0.5002785622061957, 0.11985590162351928, 0.8231790230502019, 0.05723173035125403, 0.0771730963844553, 0.030390718271065147]\n",
      "11156/11156 [==============================] - 20s 2ms/sample - loss: 0.4095 - val_loss: 0.3659\n",
      "Epoch 7/70\n",
      "3497/3497 [==============================] - 2s 431us/sample\n",
      "[0.5007894883636345, 0.12006751124848826, 0.8249792179336846, 0.05448280826025928, 0.07546791742267546, 0.029772636192042692]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.4090 - val_loss: 0.3649\n",
      "Epoch 8/70\n",
      "3497/3497 [==============================] - 1s 414us/sample\n",
      "[0.5005801201021953, 0.12024875380113843, 0.8264160707305929, 0.04969370885594085, 0.07228943840270358, 0.028554389706142394]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3968 - val_loss: 0.3670\n",
      "Epoch 9/70\n",
      "3497/3497 [==============================] - 2s 439us/sample\n",
      "[0.5004622585763372, 0.11980410655046622, 0.8259371197982901, 0.049074997860997865, 0.0722035109881877, 0.028541357047484766]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3897 - val_loss: 0.3603\n",
      "Epoch 10/70\n",
      "3497/3497 [==============================] - 1s 427us/sample\n",
      "[0.5006970211678765, 0.12020092332063184, 0.8266307728726596, 0.04918080001056105, 0.07192188694262351, 0.02842740834958209]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3749 - val_loss: 0.3564\n",
      "Epoch 11/70\n",
      "3497/3497 [==============================] - 2s 448us/sample\n",
      "[0.49590364786564706, 0.11865074768960834, 0.7675436423392624, 0.07375575714785712, 0.11643473541188361, 0.04318946148362856]\n",
      "11156/11156 [==============================] - 20s 2ms/sample - loss: 0.3697 - val_loss: 0.3520\n",
      "Epoch 12/70\n",
      "3497/3497 [==============================] - 1s 421us/sample\n",
      "[0.5005024574671733, 0.11993500560552935, 0.8264656173787621, 0.05039997581651436, 0.07293312836804472, 0.02880915273811202]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3535 - val_loss: 0.3475\n",
      "Epoch 13/70\n",
      "3497/3497 [==============================] - 1s 428us/sample\n",
      "[0.4994826265167585, 0.11962359301674057, 0.7718321799974677, 0.07549165374630731, 0.11900147476530397, 0.0444701337774966]\n",
      "11156/11156 [==============================] - 20s 2ms/sample - loss: 0.3462 - val_loss: 0.3466\n",
      "Epoch 14/70\n",
      "3497/3497 [==============================] - 2s 457us/sample\n",
      "[0.5012895351262959, 0.120642796700271, 0.8272088171013008, 0.05051084077581209, 0.07293105663667233, 0.02884108483368869]\n",
      "11156/11156 [==============================] - 20s 2ms/sample - loss: 0.3446 - val_loss: 0.3448\n",
      "Epoch 15/70\n",
      "3497/3497 [==============================] - 1s 421us/sample\n",
      "[0.5025991030053709, 0.12052711913563348, 0.7789834128832296, 0.0769702600795727, 0.12078638195337306, 0.04565126299242328]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3441 - val_loss: 0.3461\n",
      "Epoch 16/70\n",
      "3497/3497 [==============================] - 1s 423us/sample\n",
      "[0.500959921285942, 0.12037186153636759, 0.8265647106751006, 0.05052940017292126, 0.07318085518805408, 0.028932131390476748]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3433 - val_loss: 0.3457\n",
      "Epoch 17/70\n",
      "3497/3497 [==============================] - 2s 433us/sample\n",
      "[0.5006334429172239, 0.12001641337887985, 0.8271592704531314, 0.047868676349371655, 0.07139056123104859, 0.028225570986867874]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3424 - val_loss: 0.3450\n",
      "Epoch 18/70\n",
      "3497/3497 [==============================] - 2s 435us/sample\n",
      "[0.5014610236419015, 0.12096017614540881, 0.8275226125397062, 0.04999838651134911, 0.07277430967708208, 0.028791591879389882]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3418 - val_loss: 0.3494\n",
      "Epoch 19/70\n",
      "3497/3497 [==============================] - 2s 432us/sample\n",
      "[0.5005215862323374, 0.12011140897177063, 0.8272583637494701, 0.04604304905323074, 0.0701477936838963, 0.027716941646464287]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3427 - val_loss: 0.3447\n",
      "Epoch 20/70\n",
      "3497/3497 [==============================] - 1s 426us/sample\n",
      "[0.5004097150756784, 0.11991890138619565, 0.827390488144588, 0.046321142842441355, 0.0703396034958496, 0.027798780602142494]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3424 - val_loss: 0.3452\n",
      "Epoch 21/70\n",
      "3497/3497 [==============================] - 2s 436us/sample\n",
      "[0.5006456806823639, 0.12013891747548627, 0.8271262393543521, 0.047764273370772464, 0.07130633709965745, 0.02818206586569398]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3415 - val_loss: 0.3450\n",
      "Epoch 22/70\n",
      "3497/3497 [==============================] - 2s 430us/sample\n",
      "[0.5007034423974623, 0.12031623255122123, 0.8271427549037419, 0.04768818125830289, 0.07124403933825213, 0.02815618771413985]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3415 - val_loss: 0.3445\n",
      "Epoch 23/70\n",
      "3497/3497 [==============================] - 1s 423us/sample\n",
      "[0.5005686844046223, 0.12010366433966913, 0.8271923015519111, 0.04707842261654493, 0.07084344757589776, 0.02799549454000195]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3412 - val_loss: 0.3443\n",
      "Epoch 24/70\n",
      "3497/3497 [==============================] - 2s 446us/sample\n",
      "[0.5003383471144465, 0.1198272113311955, 0.8271427549037419, 0.046451639258087, 0.07043998287203192, 0.027832972426724858]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3409 - val_loss: 0.3444\n",
      "Epoch 25/70\n",
      "3497/3497 [==============================] - 2s 434us/sample\n",
      "[0.5003554681793998, 0.11981034699275948, 0.8269610838604546, 0.04711947814545807, 0.07089981133189294, 0.028016456929513087]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3411 - val_loss: 0.3443\n",
      "Epoch 26/70\n",
      "3497/3497 [==============================] - 2s 435us/sample\n",
      "[0.5005591367352774, 0.11995463424767358, 0.8271757860025213, 0.047505388093053574, 0.07113856276831006, 0.028115777360316944]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3408 - val_loss: 0.3443\n",
      "Epoch 27/70\n",
      "3497/3497 [==============================] - 2s 445us/sample\n",
      "[0.5005109226895238, 0.11992840187754866, 0.8272088171013008, 0.04716308316422131, 0.07090721849700375, 0.02802241406127805]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3409 - val_loss: 0.3443\n",
      "Epoch 28/70\n",
      "3497/3497 [==============================] - 2s 430us/sample\n",
      "[0.5006858090134133, 0.12015152560980018, 0.8274565503421472, 0.04720776573699023, 0.07091467273158147, 0.02802844746873783]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3409 - val_loss: 0.3444\n",
      "Epoch 29/70\n",
      "3497/3497 [==============================] - 1s 427us/sample\n",
      "[0.5009167978466382, 0.12021212403131108, 0.8271757860025213, 0.049044689720564555, 0.07217923631313922, 0.02853950617387627]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3410 - val_loss: 0.3444\n",
      "Epoch 30/70\n",
      "3497/3497 [==============================] - 2s 440us/sample\n",
      "[0.5003180665065096, 0.11982359825002376, 0.8273079103976393, 0.04593625986857731, 0.07009255204938564, 0.027694130358766795]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3409 - val_loss: 0.3442\n",
      "Epoch 31/70\n",
      "3497/3497 [==============================] - 2s 449us/sample\n",
      "[0.5003468487384976, 0.11983262361419007, 0.82725836374947, 0.046288001678298746, 0.07032553767368625, 0.027787709899571092]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3405 - val_loss: 0.3440\n",
      "Epoch 32/70\n",
      "3497/3497 [==============================] - 1s 428us/sample\n",
      "[0.5005210040850668, 0.11996237037898363, 0.8273409414964188, 0.04701045057467148, 0.07079462971270528, 0.02797834096972513]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3407 - val_loss: 0.3442\n",
      "Epoch 33/70\n",
      "3497/3497 [==============================] - 2s 433us/sample\n",
      "[0.5008398015688966, 0.12018626305256223, 0.8273079103976393, 0.04856874473178934, 0.07183873629799058, 0.02840274713881215]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3407 - val_loss: 0.3441\n",
      "Epoch 34/70\n",
      "3497/3497 [==============================] - 2s 440us/sample\n",
      "[0.50110030361143, 0.12033703431274617, 0.827126239354352, 0.049865888931977964, 0.07275135914928393, 0.0287727592523706]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3407 - val_loss: 0.3443\n",
      "Epoch 35/70\n",
      "3497/3497 [==============================] - 1s 424us/sample\n",
      "[0.5005684871535, 0.11994583514260476, 0.8270766927061828, 0.04783057548228663, 0.07136695854007713, 0.0282070738662158]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3406 - val_loss: 0.3442\n",
      "Epoch 36/70\n",
      "3497/3497 [==============================] - 1s 426us/sample\n",
      "[0.5006080817583514, 0.12003526190257333, 0.8273574570458085, 0.047189760857667934, 0.07091168536073653, 0.028026024859152447]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3407 - val_loss: 0.3440\n",
      "Epoch 37/70\n",
      "3497/3497 [==============================] - 2s 456us/sample\n",
      "[0.5003561991567201, 0.1198272113311955, 0.8271923015519111, 0.046633193361209725, 0.07055741165147718, 0.027880711750307915]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3409 - val_loss: 0.3440\n",
      "Epoch 38/70\n",
      "3497/3497 [==============================] - 1s 424us/sample\n",
      "[0.5004036822251534, 0.11983413757545278, 0.8269610838604546, 0.04746415252550222, 0.07113151613849382, 0.028110103040858314]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3405 - val_loss: 0.3439\n",
      "Epoch 39/70\n",
      "3497/3497 [==============================] - 1s 423us/sample\n",
      "[0.5005670251988593, 0.11990439437341276, 0.8266803195208288, 0.049080712215991876, 0.07227100924935877, 0.028567675964828843]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3404 - val_loss: 0.3440\n",
      "Epoch 40/70\n",
      "3497/3497 [==============================] - 2s 474us/sample\n",
      "[0.5007411805454285, 0.12000700457599921, 0.8267628972677775, 0.049757953732346906, 0.0727321338711892, 0.028757144663020998]\n",
      "11156/11156 [==============================] - 20s 2ms/sample - loss: 0.3404 - val_loss: 0.3439\n",
      "Epoch 41/70\n",
      "3497/3497 [==============================] - 1s 429us/sample\n",
      "[0.5008489307671492, 0.1200943795482957, 0.8267959283665571, 0.04994041452742519, 0.07284978410663591, 0.02880662795008481]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3403 - val_loss: 0.3440\n",
      "Epoch 42/70\n",
      "3497/3497 [==============================] - 1s 427us/sample\n",
      "[0.49663052958454057, 0.11889270437569627, 0.8103959878225349, 0.059720903603391516, 0.08571127748209723, 0.03326746290400185]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3405 - val_loss: 0.3443\n",
      "Epoch 43/70\n",
      "3497/3497 [==============================] - 2s 446us/sample\n",
      "[0.50046197766645, 0.11987394451181145, 0.8270436616074033, 0.04747991028462281, 0.07113422181611234, 0.02811227809834311]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3403 - val_loss: 0.3438\n",
      "Epoch 44/70\n",
      "3497/3497 [==============================] - 1s 427us/sample\n",
      "[0.5007613433365142, 0.12005002775060743, 0.8269775994098443, 0.04915933170686925, 0.07228499709252428, 0.02857896527455811]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3405 - val_loss: 0.3439\n",
      "Epoch 45/70\n",
      "3497/3497 [==============================] - 1s 419us/sample\n",
      "[0.5006735346859094, 0.11996786231259376, 0.8266968350702186, 0.04941288816989004, 0.0725004110117291, 0.028661317615046922]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3403 - val_loss: 0.3438\n",
      "Epoch 46/70\n",
      "3497/3497 [==============================] - 2s 434us/sample\n",
      "[0.5006648912761595, 0.11999903880815695, 0.8266968350702186, 0.04903018184330026, 0.07221334428798681, 0.028543821912222916]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3402 - val_loss: 0.3439\n",
      "Epoch 47/70\n",
      "3497/3497 [==============================] - 1s 427us/sample\n",
      "[0.5005591127664297, 0.11995187345847988, 0.8268619905641161, 0.048230449515573405, 0.07164512561519015, 0.028316068811610987]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3401 - val_loss: 0.3439\n",
      "Epoch 48/70\n",
      "3497/3497 [==============================] - 2s 488us/sample\n",
      "[0.5006751699228247, 0.12013093203825322, 0.8269775994098443, 0.04818028147003606, 0.07158736883401527, 0.02829337902636445]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3402 - val_loss: 0.3439\n",
      "Epoch 49/70\n",
      "3497/3497 [==============================] - 2s 432us/sample\n",
      "[0.5004921978842309, 0.11993160801150632, 0.8270932082555726, 0.04724212524128278, 0.07095787558130226, 0.028040978686883964]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3399 - val_loss: 0.3438\n",
      "Epoch 50/70\n",
      "3497/3497 [==============================] - 2s 431us/sample\n",
      "[0.5008011112236402, 0.1202167088096368, 0.8270766927061828, 0.048543255623750906, 0.07182222042019669, 0.028390034363647627]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3402 - val_loss: 0.3439\n",
      "Epoch 51/70\n",
      "3497/3497 [==============================] - 2s 445us/sample\n",
      "[0.5003667903096134, 0.11983797370286281, 0.8270766927061829, 0.04697112253125568, 0.0707880328556662, 0.027973020820760957]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3400 - val_loss: 0.3439\n",
      "Epoch 52/70\n",
      "3497/3497 [==============================] - 2s 435us/sample\n",
      "[0.5005787418313176, 0.1200819507912741, 0.8270436616074033, 0.04750139469763422, 0.07112573682628971, 0.028107511244586048]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3400 - val_loss: 0.3438\n",
      "Epoch 53/70\n",
      "3497/3497 [==============================] - 1s 426us/sample\n",
      "[0.5006852513183675, 0.12014902245173123, 0.8271097238049623, 0.0478606868920113, 0.07135995080417991, 0.028203022364843358]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3400 - val_loss: 0.3439\n",
      "Epoch 54/70\n",
      "3497/3497 [==============================] - 2s 466us/sample\n",
      "[0.5005693914130949, 0.12008386465238868, 0.8271427549037419, 0.047166992345573394, 0.07089572821133164, 0.02801569366494035]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3396 - val_loss: 0.3439\n",
      "Epoch 55/70\n",
      "3497/3497 [==============================] - 2s 436us/sample\n",
      "[0.5005211773673414, 0.12005915003116734, 0.8271757860025213, 0.046818121581054715, 0.07066325338771465, 0.02792220941733507]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3402 - val_loss: 0.3438\n",
      "Epoch 56/70\n",
      "3497/3497 [==============================] - 2s 433us/sample\n",
      "[0.5005118269491188, 0.12006214762924558, 0.8272748792988599, 0.046473658808846276, 0.07043148449886401, 0.027829607491215005]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3400 - val_loss: 0.3438\n",
      "Epoch 57/70\n",
      "3497/3497 [==============================] - 2s 530us/sample\n",
      "[0.5004823137398103, 0.12003435371930876, 0.8271097238049623, 0.04680920728642614, 0.07066176348969995, 0.027921014468622267]\n",
      "11156/11156 [==============================] - 20s 2ms/sample - loss: 0.3400 - val_loss: 0.3438\n",
      "Epoch 58/70\n",
      "3497/3497 [==============================] - 2s 433us/sample\n",
      "[0.5005499595993295, 0.12007050614569163, 0.8271097238049623, 0.047161981973735286, 0.07089488571801449, 0.028015017100695965]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3399 - val_loss: 0.3439\n",
      "Epoch 59/70\n",
      "3497/3497 [==============================] - 2s 439us/sample\n",
      "[0.5004717225869171, 0.12018985026585646, 0.8272088171013008, 0.04646321969082521, 0.07042974793436395, 0.027828214124099675]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3400 - val_loss: 0.3439\n",
      "Epoch 60/70\n",
      "3497/3497 [==============================] - 2s 449us/sample\n",
      "[0.500442940354929, 0.12017815480603626, 0.8272748792988599, 0.046111313807072105, 0.07019673681869637, 0.027734931436790913]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3401 - val_loss: 0.3439\n",
      "Epoch 61/70\n",
      "3497/3497 [==============================] - 2s 475us/sample\n",
      "[0.500336964594077, 0.11997150342174064, 0.8272913948482497, 0.045843662151297274, 0.07002744390213361, 0.027667247712467938]\n",
      "11156/11156 [==============================] - 20s 2ms/sample - loss: 0.3398 - val_loss: 0.3438\n",
      "Epoch 62/70\n",
      "3497/3497 [==============================] - 1s 427us/sample\n",
      "[0.5005300180282135, 0.1202293577287356, 0.8273079103976394, 0.04647498077525147, 0.07043169219405387, 0.027829774156548345]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3400 - val_loss: 0.3438\n",
      "Epoch 63/70\n",
      "3497/3497 [==============================] - 1s 427us/sample\n",
      "[0.5005300180282135, 0.1202293577287356, 0.8273079103976394, 0.04647498077525147, 0.07043169219405387, 0.027829774156548345]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3399 - val_loss: 0.3438\n",
      "Epoch 64/70\n",
      "3497/3497 [==============================] - 1s 422us/sample\n",
      "[0.5004046104535961, 0.12001031584547459, 0.8272913948482497, 0.04620397887425773, 0.07026184950019491, 0.027761649676028777]\n",
      "11156/11156 [==============================] - 20s 2ms/sample - loss: 0.3399 - val_loss: 0.3438\n",
      "Epoch 65/70\n",
      "3497/3497 [==============================] - 2s 489us/sample\n",
      "[0.5004722563131152, 0.12005166549745108, 0.8272913948482497, 0.04656192314142914, 0.07049585796890753, 0.02785605163958962]\n",
      "11156/11156 [==============================] - 20s 2ms/sample - loss: 0.3401 - val_loss: 0.3439\n",
      "Epoch 66/70\n",
      "3497/3497 [==============================] - 2s 498us/sample\n",
      "[0.5006269798459189, 0.12015996455946516, 0.8273244259470292, 0.04727644237446689, 0.07096363154941404, 0.028045618167607415]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3401 - val_loss: 0.3439\n",
      "Epoch 67/70\n",
      "3497/3497 [==============================] - 2s 431us/sample\n",
      "[0.5004916881268806, 0.12006881310080558, 0.8273244259470292, 0.04656644661088497, 0.07049660576082756, 0.027856653692928654]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3397 - val_loss: 0.3439\n",
      "Epoch 68/70\n",
      "3497/3497 [==============================] - 2s 453us/sample\n",
      "[0.5004240422673616, 0.12002577528747077, 0.8273244259470292, 0.046207925176917436, 0.0702624986861417, 0.027762171455589277]\n",
      "11156/11156 [==============================] - 20s 2ms/sample - loss: 0.3399 - val_loss: 0.3437\n",
      "Epoch 69/70\n",
      "3497/3497 [==============================] - 1s 428us/sample\n",
      "[0.500298634692744, 0.11980673340420973, 0.8273079103976393, 0.04593625986857731, 0.07009255204938564, 0.027694130358766795]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3399 - val_loss: 0.3437\n",
      "Epoch 70/70\n",
      "3497/3497 [==============================] - 1s 422us/sample\n",
      "[0.5003662805522632, 0.11984977121754456, 0.8273079103976393, 0.04629478130254485, 0.07032665912407149, 0.02778861259610618]\n",
      "11156/11156 [==============================] - 19s 2ms/sample - loss: 0.3400 - val_loss: 0.3438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa13c748828>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train neural network\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam())\n",
    "\n",
    "model.fit(train_x, train_y,\n",
    "        batch_size=batch_size,\n",
    "        epochs=70,\n",
    "        initial_epoch=0,  # If you are continuing a interrupted section change here\n",
    "        validation_split=0.2,\n",
    "        shuffle='batch',  # Because our dataset is an HDF5 file\n",
    "        callbacks=callbacks,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (confusion_matrix,\n",
    "                             precision_score, recall_score, f1_score,\n",
    "                             precision_recall_curve, average_precision_score)\n",
    "\n",
    "def get_optimal_precision_recall(y_true, y_score):\n",
    "    \"\"\"Find precision and recall values that maximize f1 score.\"\"\"\n",
    "    n = np.shape(y_true)[1]\n",
    "    opt_precision = []\n",
    "    opt_recall = []\n",
    "    opt_threshold = []\n",
    "    for k in range(n):\n",
    "        # Get precision-recall curve\n",
    "        precision, recall, threshold = precision_recall_curve(y_true[:, k], y_score[:, k])\n",
    "        # Compute f1 score for each point (use nan_to_num to avoid nans messing up the results)\n",
    "        f1_score = np.nan_to_num(2 * precision * recall / (precision + recall))\n",
    "        # Select threshold that maximize f1 score\n",
    "        index = np.argmax(f1_score)\n",
    "        opt_precision.append(precision[index])\n",
    "        opt_recall.append(recall[index])\n",
    "        t = threshold[index-1] if index != 0 else threshold[0]-1e-10\n",
    "        opt_threshold.append(t)\n",
    "    print (f1_score, index)\n",
    "    return np.array(opt_precision), np.array(opt_recall), np.array(opt_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_score = model.predict(dev_x, batch_size=32, verbose=1)\n",
    "# y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt_threshold = [0.15503691, 0.10315302, 0.02896456, 0.10009797, 0.07985777, 0.26683953, 0.12415724, 0.03354117]\n",
    "# concatednate = []\n",
    "# for threshold_index in range(len(opt_threshold)):\n",
    "#     temp_y = y_score[:, threshold_index]\n",
    "#     print (temp_y[temp_y > opt_threshold[threshold_index]].shape)\n",
    "    \n",
    "#     temp_y[temp_y > opt_threshold[threshold_index]] = 0.99\n",
    "#     temp_y[temp_y <= opt_threshold[threshold_index]] = 0.01\n",
    "#     concatednate.append(temp_y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatednate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
